# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
The dataset contains data about features of customers who either subscribed or didn't subscribe to a fixed term deposit with a financial institution. The goal is to predict whether or not a customer will subscribe given a bunch of features, e.g. job, education. 
**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model from auto ml 

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
Under a single workspace a cluster is provisioned. The actual hyperparameter tuning job creates containers for every hyperparameter it samples using the specified image in the configuration to run the train.py script. The train.py script then downloads the data from an external source, splits it into a training and test set and uses the hyperparameters passed to it from the container to log the obtained metric which coincides with the metric from the config, using an sklearn learn logistic regression model. The containers are essentially producers, in the streaming sense, that have their messages consumed by the hyperparameter job running to determine the best run and to apply the early termination policies specified in the configuration. 
**What are the benefits of the parameter sampler you chose?**
It is much faster than grid search/bayesian/evolutionary without sacrificing much (if any) efficacy. It also gives flexibility for swapping out sample distributions to incorporate more knowledge about the parameter search space (in this case, it was chosen to be uniform, having maximum entropy implying that nothing is assumed/known about the parameter space distribution).   
**What are the benefits of the early stopping policy you chose?**
BanditPolicy stops after it stops seeing sufficient improvements from the best found metric after a specified number of iteratons for every interval following of a specificed size. This gives a burn-in period for a sufficient number of iterations before the policy is applied and a sufficient interval delay, so that a premature termination can be avoided (through sampling variance control by the interval parameter). 

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
